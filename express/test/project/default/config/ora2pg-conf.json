{"COMMON":{"values":{"IMPORT":{"value":"common.conf","description":"A config file that may contain any of the following configuration directives","include":false},"LAST_MODIFIED":{"value":123456789,"description":"Timestamp of the last time the configuration for this project was updated.","include":false,"type":"timestamp"}},"title":"Include a common config file"},"INPUT":{"values":{"INPUT_FILE":{"value":"oracle_package_body.sql","description":"A file containing PL/SQL Oracle Code for a function, procedure or a full package body. Used to prevent Ora2Pg from connecting to an Oracle database just apply the conversion tool to the content of the file. Can only be used with the following export types: PROCEDURE, FUNCTION or PACKAGE","include":true},"ORACLE_HOME":{"value":"/usr/lib/oracle/21/client64","description":"Full path to the Oracle home directory","include":true},"ORACLE_DSN":{"value":"dbi:Oracle:host=mydb.mydom.fr;sid=SIDNAME;port=1521","description":"A  DBD::Oracle Perl module database connection","include":false,"class":"basic"},"ORACLE_USER":{"value":"system","description":"Ideally a user that has been granted the DBA role","include":false,"class":"basic"},"ORACLE_PWD":{"value":"manager","description":"Database password","include":false,"class":"basic","type":"password"},"USER_GRANTS":{"value":0,"flag":true,"description":"Enable to connect as simple user that does not have DBA privileges. Ora2pg will query the ALL_ catalog views instead of DBA_. Note: this will not work with a GRANT export","include":true},"DEBUG":{"value":1,"flag":true,"description":"Trace output to stderr","include":true},"ORA_INITIAL_COMMAND":{"value":"","description":"An initial command to Oracle, just after the connection. For example to unlock a policy before reading objects or to set some session parameters. This directive can be used multiple times.","include":false}},"title":"Oracle connection or input file","class":"basic"},"SCHEMA":{"values":{"EXPORT_SCHEMA":{"value":0,"flag":true,"description":"Export Oracle schema to PostgreSQL schema","include":true},"SCHEMA":{"value":"","description":"The Oracle schema/owner to use","include":true,"class":"basic"},"CREATE_SCHEMA":{"value":1,"flag":true,"description":"Enable/disable the CREATE SCHEMA SQL command at start of the output file for TABLE export type. It is enabled by default","include":true},"COMPILE_SCHEMA":{"value":0,"flag":true,"description":"Force Oracle to compile schemas before exporting code. When this directive is enabled and the SCHEMA property is set only invalid objects in the specified schema will be recompiled. If SCHEMA property is not set then all schemas will be recompiled","include":true},"PG_SCHEMA":{"value":"","description":"By default the PostgreSQL search_path will be set to the schema name specified in the SCHEMA directive when EXPORT_SCHEMA is enabled. PG_SCHEMA can be used to override this behavior. The value can be a single schema or a comma delimited list. Note: for exports of type TABLE the value must be a single schema","include":false},"POSTGIS_SCHEMA":{"value":"","description":"Add a specific schema to the search path for PostGis functions.","include":false},"SYSUSERS":{"value":"OE,HR","description":"A comma separated list of users to exclude from Oracle extraction. All object owned by the following system users are suppressed by default: CTXSYS,DBSNMP,EXFSYS,LBACSYS,MDSYS,MGMT_VIEW,OLAPSYS,ORDDATA,OWBSYS, ORDPLUGINS,ORDSYS,OUTLN,SI_INFORMTN_SCHEMA,SYS,SYSMAN,SYSTEM,WK_TEST, WKSYS,WKPROXY,WMSYS,XDB,APEX_PUBLIC_USER,DIP,FLOWS_020100,FLOWS_030000, FLOWS_040100,FLOWS_010600,FLOWS_FILES,MDDATA,ORACLE_OCM,SPATIAL_CSW_ADMIN_USR, SPATIAL_WFS_ADMIN_USR,XS$NULL,PERFSTAT,SQLTXPLAIN,DMSYS,TSMSYS,WKSYS, APEX_040200,DVSYS,OJVMSYS,GSMADMIN_INTERNAL,APPQOSSYS.  Set this directive to add additional users to this list","include":false},"LOOK_FORWARD_FUNCTION":{"value":"SCOTT,OE","description":"Comma separated list of schema to read to find metadata for functions and procedures that are used in the current schema export. Used for exports where the Oracle tables and stored procedures reside in different database schemas.  Ora2Pg will look for functions, procedures and packages in the specified schemas before proceeding with the schema export","include":false},"NO_FUNCTION_METADATA":{"value":0,"flag":true,"description":"Force Ora2Pg to not look for function declaration. Note that this will prevent rewrite function replacement calls. Do not enable it unless looking forward at function breaks other export","include":true}},"title":"Oracle schema to export and PostgreSQL schema to use","class":"basic"},"ENCODING":{"values":{"NLS_LANG":{"value":"AMERICAN_AMERICA.AL32UTF8","description":"Enforce the default language setting for the Oracle database encoding. May be used with multibyte character sets like UTF8. Tip: Ora2Pg uses default values for this parameter, do not change them unless you encounter problems with the default encoding. This will set $ENV{NLS_LANG} to the given value","include":false},"NLS_NCHAR":{"value":"AL32UTF8","description":"Sets $ENV{NLS_NCHAR} to the given value","include":false},"CLIENT_ENCODING":{"value":"UTF8","description":"By default PostgreSQL client encoding is automatically set to UTF8 to avoid encoding issue. If you have changed the value of NLS_LANG you might have to change the encoding of the PostgreSQL client","include":false}},"title":"Oracle and PostgreSQL client encoding"},"EXPORT":{"values":{"TYPE":{"value":"PACKAGE","enum":["TABLE","VIEW","GRANT","SEQUENCE","TABLESPACE","TRIGGER","FUNCTION","PROCEDURE","PACKAGE","INSERT","COPY","PARTITION","TYPE","FDW","MVIEW","QUERY","KETTLE","DBLINK","SYNONYM","DIRECTORY","LOAD","TEST","TEST_VIEW","SHOW_VERSION","SHOW_SCHEMA","SHOW_TABLE","SHOW_COLUMN","SHOW_REPORT"],"description":"Type of export. Value can be one the following: TABLE (export tables, constraints & indexes), PACKAGE, INSERT (export data from table as INSERT statement), COPY (export data from table as COPY statement), VIEW, GRANT, SEQUENCE, TRIGGER,  FUNCTION, PROCEDURE, TABLESPACE (PostgreSQL >= 8 only), TYPE (user defined Oracle types), PARTITION (export range or list partition (PostgreSQL >= v8.4)), FDW (export table as foreign data wrapper tables), MVIEW (export materialized view as snapshot refresh view), QUERY (convert Oracle SQL queries from a file.), KETTLE (generate XML ktr template files to be used by Kettle)","include":true,"class":"basic"},"DISABLE_COMMENT":{"value":0,"flag":true,"description":"Suppress the export comments for table and column definitions.","include":true},"ALLOW":{"value":"PREFIX_.*","description":"Objects to export. By default Ora2Pg exports all objects. Value must be a list of object names, a space separated regex or % wildcard for use with the LIKE operator","include":false,"class":"basic"},"EXCLUDE":{"value":"OTHER_.*","description":"Objects to exclude from export process. By default none. Value must be a list of object names, a space separated regex or % wildcard for use with the LIKE operator","include":false,"class":"basic"},"VIEW_AS_TABLE":{"value":"VIEW_NAME","description":"Views to export as tables. By default none. Value must be a list of view names or regexp separated by space. If the object name is a view and the export type is TABLE, the view will be exported as a create table statement. If export type is COPY or INSERT, the corresponding data will be exported","include":false},"NO_VIEW_ORDERING":{"value":0,"flag":true,"description":"By default Ora2Pg tries to order views to avoid error at import time with nested views. With a huge number of view this can take a very long time, enable NO_VIEW_ORDERING to bypass this ordering","include":true},"GRANT_OBJECT":{"value":"TABLE","enum":["TABLE","VIEW","MATERIALIZED VIEW","SEQUENCE","PROCEDURE","FUNCTION","PACKAGE BODY","TYPE","SYNONYM","DIRECTORY","USER"],"description":"Limits the list of objects for which privileges will be exported. Default is export for all objects. For example set it to TABLE if you just want to export privilege on tables. This directive prevents the export of users unless it is set to USER. In this case only users definitions are exported.","include":false},"EXTERNAL_TO_FDW":{"value":1,"flag":true,"description":"By default Ora2Pg will export external tables as file_fdw tables. Disable this property if you don't want to export those tables at all","include":true},"TRUNCATE_TABLE":{"value":0,"flag":true,"description":"Add a TRUNCATE TABLE instruction before loading data on COPY and INSERT export. When activated, the instruction will be added only if there's no global DELETE clause or one specific to the current table","include":true},"USE_TABLESPACE":{"value":0,"description":"Export all tables, index constraints, and indexes using the tablespace name defined in Oracle database. This works only with tablespaces other than TEMP, USERS and SYSTEM.","include":true},"REORDERING_COLUMNS":{"value":0,"flag":true,"description":"Reorder columns and minimized the footprint on disk so that more rows fit on a data page. Default is same order than in Oracle table definition","include":true},"REPLACE_QUERY":{"value":"EMPLOYEES[SELECT e.id,e.fisrtname,lastname FROM EMPLOYEES e JOIN EMP_UPDT u ON (e.id=u.id AND u.cdate>'2014-08-01 00:00:00')]","description":"Custom query to extract data from an Oracle table. Overrides the default Ora2Pg \"SELECT * FROM table\" query to extract data. The format is TABLENAME[SQL_QUERY]. You can define multiple REPLACE_QUERY lines","include":false}},"title":"Export type and filters","class":"basic"},"FULL_TEXT_SEARCH":{"values":{"CONTEXT_AS_TRGM":{"value":0,"flag":true,"description":"Translate Oracle Text indexes into PostgreSQL indexes using pg_trgm extension","include":true},"FTS_INDEX_ONLY":{"value":1,"flag":true,"description":"By default Ora2Pg creates a function-based indexes to translate Oracle Text indexes. Disable this directive to force Ora2Pg to create an extra tsvector column with a dedicated triggers for FTS indexes","include":true},"FTS_CONFIG":{"value":"pg_catalog.french","description":"Use this directive to force text search configuration to use. When it is not set, Ora2Pg will autodetect the stemmer used by Oracle for each index and pg_catalog.english if nothing is found.","include":false},"USE_UNACCENT":{"value":0,"flag":true,"description":"Enable this directive to perform your text search in an accent insensitive way. Ora2Pg will create an helper function over unaccent() and create the pg_trgm indexes using this function. With FTS Ora2Pg will redefine your text search configuration","include":true},"USE_LOWER_UNACCENT":{"value":0,"flag":true,"description":"Same as USE_UNACCENT but call lower() in the unaccent_immutable() function","include":true}},"title":"Full text search export behavior"},"DATA_DIFF":{"values":{"DATADIFF":{"value":0,"flag":true,"description":"Enable DATADIFF functionality. EXPERIMENTAL! Not yet working correctly with partitioned tables, parallelism, and direct Postgres connection! Test before using in production! This feature affects SQL output for data (INSERT or COPY). The deletion and (re-)importing of data is redirected to temporary tables (with configurable suffix) and matching entries (i.e. quasi-unchanged rows) eliminated before actual application of the DELETE, UPDATE and INSERT. Optional functions can be specified that are called before or after the actual DELETE, UPDATE and INSERT per table, or after all tables have been processed","include":true},"DATADIFF_UPDATE_BY_PKEY":{"value":0,"flag":true,"description":"Use UPDATE where changed columns can be matched by the primary key (otherwise rows are DELETEd and re-INSERTed, which may interfere with inverse foreign keys relationships!)","include":true},"DATADIFF_DEL_SUFFIX":{"value":"_del","description":"Suffix for temporary tables holding rows to be deleted","include":true},"DATADIFF_UPD_SUFFIX":{"value":"_upd","description":"Suffix for temporary tables holding rows to be updated","include":true},"DATADIFF_INS_SUFFIX":{"value":"_ins","description":"Suffix for temporary tables holding rows to be inserted","include":true},"DATADIFF_WORK_MEM":{"value":"256 MB","description":"work_mem parameter to keep temp tables in memory for sorting, etc.","include":false},"DATADIFF_TEMP_BUFFERS":{"value":"512 MB","description":"temp_buffers parameter to keep temp tables in memory for sorting, etc.","include":false},"DATADIFF_BEFORE":{"value":"my_datadiff_handler_function","description":"Function to be called (via SELECT) after the temporary tables have been reduced (by removing matching rows) and immediately before the actual DELETE and INSERT are performed. Must accept four arguments ideally of type \"regclass\" representing the table name and the corresponding temp table names for  \"deletions\", \"updates\", and \"inserts\". Called before re-activation of triggers, indexes, etc. (if configured)","include":false},"DATADIFF_AFTER":{"value":"my_datadiff_handler_function","description":"Function to be called (via SELECT) after the temporary tables have been reduced (by removing matching rows) immediately after the actual DELETE and INSERT are performed. Must accept four arguments ideally of type \"regclass\" representing the table name and the corresponding temp table names for  \"deletions\", \"updates\", and \"inserts\". Called before re-activation of triggers, indexes, etc. (if configured)","include":false},"DATADIFF_AFTER_ALL":{"value":"my_datadiff_bunch_handler_function","description":"Another function can be called (via SELECT) right before the entire COMMIT (i.e., after re-activation of indexes, triggers, etc.), which will be passed in Postgres ARRAYs of the table names of the real tables, the \"deletions\", the \"updates\" and the \"insertions\" temp tables, respectively, with same array index positions belonging together. So this function should take four arguments of type regclass[]","include":false}},"title":"Only delete and insert actually changed rows"},"CONSTRAINT":{"values":{"SKIP":{"value":"fkeys pkeys ukeys indexes checks","description":"Turning off certain schema features in postgres during schema export. Values can be : fkeys, pkeys, ukeys, indexes, checks separated by a space character","include":false},"KEEP_PKEY_NAMES":{"value":0,"flag":true,"description":" By default, primary key names in the source database are ignored, and default key names are created in the target database. If this is enabled, primary key names are kept","include":true},"PKEY_IN_CREATE":{"value":0,"flag":true,"description":"Enable this directive if you want to add primary key definitions inside the create table statements. If disabled (the default) primary key definition will be added with an alter table statement. Enable it if you are exporting to GreenPlum PostgreSQL database","include":true},"FKEY_ADD_UPDATE":{"value":"never","description":"This directive allow you to add an ON UPDATE CASCADE option to a foreign key when a ON DELETE CASCADE is defined or always. Oracle does not support this feature, you have to use trigger to operate the ON UPDATE CASCADE. As PostgreSQL has this feature, you can choose how to add the foreign key option. There are three value to this directive: never, the default means foreign keys will be declared exactly like in Oracle. The second value is delete, that mean that the ON UPDATE CASCADE option will be added only if the ON DELETE CASCADE is already defined on the foreign Keys. The last value, always, will force all foreign keys to be defined using the update option","include":true},"FKEY_DEFERRABLE":{"value":0,"flag":true,"description":"Export deferrable foreign key constraints. When exporting tables, Ora2Pg normally exports constraints as they are; if they are non-deferrable they are exported as non-deferrable. Non-deferrable constraints will probably cause problems when attempting to import data to PostgreSQL. Use this flag to override the default behavior","include":true},"DEFER_FKEY":{"value":0,"flag":true,"description":"Add a command to defer all foreign key constraints during data export and the import will be done in a single transaction. This will work only if foreign keys have been exported as deferrable and you are not using direct import to PostgreSQL (PG_DSN is not defined). Constraints will then be checked at the end of the transaction. This directive can also be enabled if you want to force all foreign keys to be created as deferrable and initially deferred during schema export (TABLE export type)","include":true},"DROP_FKEY":{"value":0,"flag":true,"description":"Drop all foreign keys before all data import and recreate them at the end of the import. If deferring foreign keys is not possible due to the amount of data in a single transaction, you've not exported foreign keys as deferrable or you are using direct import to PostgreSQL, you can use the DROP_FKEY directive. It will drop all foreign keys before all data import and recreate them at the end of the import","include":true}},"title":"Constraints export and import behavior"},"TRIGGERS_AND_SEQUENCES":{"values":{"DISABLE_SEQUENCE":{"value":0,"flag":true,"description":"Disable update of sequences on all tables in COPY or INSERT mode","include":true},"DISABLE_TRIGGERS":{"value":0,"flag":true,"description":"Disable triggers on all tables in COPY or INSERT mode. Available modes are USER (user defined triggers) and ALL (includes RI system triggers). Default is not to add SQL statement to disable trigger. If you want to disable triggers during data migration, set the value to USER if your are connected as non superuser and ALL if you are connected as PostgreSQL superuser. A value of enabled is equal to USER.","include":true}},"title":"Trigger and sequence behavior","include":true},"OBJECT_MODIFICATION":{"values":{"MODIFY_STRUCT":{"value":"TABLE_TEST(dico,dossier)","description":"Limits the list of fields to extract data from. Works only with export type INSERT or COPY","include":false},"REPLACE_TABLES":{"value":"ORIG_TB_NAME1:NEW_TB_NAME1 ORIG_TB_NAME2:NEW_TB_NAME2","description":"Change table names during data extraction","include":false},"REPLACE_COLS":{"value":"TB_NAME(ORIG_COLNAME1:NEW_COLNAME1,ORIG_COLNAME2:NEW_COLNAME2","description":"Change column names during export","include":false},"PRESERVE_CASE":{"value":0,"flag":true,"description":"By default all object names are converted to lower case, if you want to preserve Oracle object name as-is set this to enabled. Not recommended unless you always quote all tables and columns on all your scripts","include":true},"INDEXES_SUFFIX":{"value":"_idx","description":"Add the given value as suffix to index names. Useful if you have indexes with same name as tables","include":false},"INDEXES_RENAMING":{"value":0,"flag":true,"description":"Rename all indexes using tablename_columns_names. Could be very useful for database that have multiple occurrences of index names that use the same name as a table, which is not allowed by PostgreSQL. Disabled by default","include":true},"USE_INDEX_OPCLASS":{"value":0,"description":"Convert indexes defined on varchar2() and char() columns to use text_pattern_ops, varchar_pattern_ops, and bpchar operator classes.          Operator classes text_pattern_ops, varchar_pattern_ops, and bpchar_pattern_ops support B-tree indexes on the corresponding types. The difference from the default operator classes is that the values are compared strictly character by character rather than according to the locale-specific collation rules. This makes these operator classes suitable for use by queries involving pattern matching expressions (LIKE or POSIX regular expressions) when the database does not use the standard \"C\" locale. If you enable, with value 1, this will force Ora2Pg to export all indexes defined on varchar2() and char() columns using those operators. If you set it to a value greater than 1 it will only change indexes on columns where the character limit is greater or equal than this value. For example, set it to 128 to create these kind of indexes on columns of type varchar2(N) where N >= 128.","include":true},"PREFIX_PARTITION":{"value":0,"flag":true,"description":"Enable if you want that your partition table name will be exported using the parent table name. Disabled by default. Note: if you have multiple partitioned table, when exported to PostgreSQL some partitions could have the same name but different parent tables. This is not allowed, table name must be unique.","include":true},"PREFIX_SUB_PARTITION":{"value":1,"flag":true,"description":"Disable if your sub-partitions are dedicated to your partition","include":true},"DISABLE_PARTITION":{"value":0,"flag":true,"description":"If you don't want to reproduce the partitioning like in Oracle and want to export all partitioned Oracle data into the main single table in PostgreSQL enable this directive. Ora2Pg will export all data into the main table name. Default is to use partitioning, Ora2Pg will export data from each partition and import them into the PostgreSQL dedicated partition table.","include":true},"WITH_OID":{"value":0,"flag":true,"description":"Activating this will force Ora2Pg to add WITH (OIDS) when creating tables or views as tables. Default is same as PostgreSQL, disabled.","include":true},"ORA_RESERVED_WORDS":{"value":"audit,comment,references","description":"Allow escaping of column name using Oracle reserved words","include":true},"USE_RESERVED_WORDS":{"value":0,"flag":true,"description":"Enable if you have tables or column names that are a reserved word for PostgreSQL. Ora2Pg will double quote the name of the object","include":true},"DISABLE_UNLOGGED":{"value":0,"flag":true,"description":"Enable to export all tables as normal tables ignoring the NOLOGGING attribute","include":true}},"title":"Object structure and name modifications"},"OUTPUT":{"values":{"PG_DSN":{"value":"dbi:Pg:dbname=test_db;host=localhost;port=5432","description":"Send export directly to a PostgreSQL database (data exports only). This will disable file output.","include":false},"PG_USER":{"value":"test","description":"PostgresSQL username","include":false},"PG_PWD":{"value":"test","type":"password","description":"PostgresSQL password","include":false},"OUTPUT":{"value":"package.sql","description":"By default all output is dump to STDOUT if not send directly to postgresql database (see above). Give a filename to save export to it. If you want a Gzip'd compressed file just add the extension .gz to the filename (you need perl module Compress::Zlib from CPAN). Add extension .bz2 to use Bzip2 compression","include":true,"class":"basic"},"OUTPUT_DIR":{"value":"/project","description":"Base directory where all dumped files must be written","include":false},"BZIP2":{"value":"BZIP2","description":"Path to the bzip2 program. See OUTPUT directive","include":true},"FILE_PER_CONSTRAINT":{"value":0,"flag":true,"description":"Allow object constraints to be saved in a separate file during schema export. The file will be named CONSTRAINTS_OUTPUT. Where OUTPUT is the value of the corresponding configuration directive. You can use .gz xor .bz2 extension to enable compression. Default is to save all data in the OUTPUT file. This directive is usable only with TABLE export type","include":true},"FILE_PER_INDEX":{"value":0,"flag":true,"description":"Allow indexes to be saved in a separate file during schema export. The file will be named INDEXES_OUTPUT. Where OUTPUT is the value of the corresponding configuration directive. You can use the .gz, .xor, or .bz2 file extension to enable compression. Default is to save all data in the OUTPUT file. This directive is usable only with TABLE or TABLESPACE export type.  With the TABLESPACE export, it is used to write \"ALTER INDEX ... TABLESPACE ...\" into a separate file named TBSP_INDEXES_OUTPUT that can be loaded at end of the migration after the indexes creation to move the indexes.","include":true},"FILE_PER_FKEYS":{"value":0,"flag":true,"description":"Allow foreign key declaration to be saved in a separate file during schema export. By default foreign keys are exported into the main output file or in the CONSTRAINT_output.sql file. When enabled foreign keys will be exported into a file named FKEYS_output.sql","include":true},"FILE_PER_TABLE":{"value":0,"flag":true,"description":"Allow data export to be saved in one file per table/view. The files will be named as tablename_OUTPUT. Where OUTPUT is the value of the corresponding configuration directive. You can use .gz xor .bz2 extension to enable compression. Default is to save all data in one file. This is usable only during INSERT or COPY export type","include":true},"FILE_PER_FUNCTION":{"value":0,"flag":true,"description":"Allow function export to be saved in one file per function/procedure. The files will be named as funcname_OUTPUT. Where OUTPUT is the value of the corresponding configuration directive. You can use .gz xor .bz2 extension to enable compression. Default is to save all data in one file. It is usable during FUNCTION, PROCEDURE, TRIGGER and PACKAGE export type","include":true},"BINMODE":{"value":"utf8","description":"By default Ora2Pg will force Perl to use utf8 I/O encoding. This is done through a call to the Perl pragma: `use open ':utf8';` You can override this encoding by using the BINMODE directive, for example you can set it to :locale to use your locale or iso-8859-7, it will respectively use `use open ':locale';` or `use open ':encoding(iso-8859-7)';`","include":false},"STOP_ON_ERROR":{"value":1,"flag":true,"description":"Set it to 0 to not include the call to \\set ON_ERROR_STOP ON in all SQL scripts.","include":true},"COPY_FREEZE":{"value":0,"flag":true,"description":"Enable this directive to use COPY FREEZE instead of a simple COPY to export data with rows already frozen. This is intended as a performance option for initial data loading. Rows will be frozen only if the table being loaded has been created or truncated in the current subtransaction. This will only works with export to file and when -J or ORACLE_COPIES is not set or default to 1. It can be used with direct import into PostgreSQL under the same condition but -j or JOBS must also be unset or default to 1","include":true},"CREATE_OR_REPLACE":{"value":1,"flag":true,"description":"By default Ora2Pg uses CREATE OR REPLACE in function DDL. If you need not to override existing functions disable this configuration directive and the generated DDL will not include 'OR REPLACE'","include":true},"PG_INITIAL_COMMAND":{"value":"","description":"Send an initial command to PostgreSQL just after the connection. For example to set some session parameters. This directive can be used multiple time","include":false}},"title":"Control output to file or PostgreSQL database","class":"basic"},"TYPE":{"values":{"DATA_TYPE":{"value":"DATE:timestamp,LONG:text,LONG RAW:bytea,CLOB:text,NCLOB:text,BLOB:bytea,BFILE:bytea,RAW:bytea,ROWID:oid,FLOAT:double precision,DEC:decimal,DECIMAL:decimal,DOUBLE PRECISION:double precision,INT:numeric,INTEGER:numeric,REAL:real,SMALLINT:smallint,BINARY_FLOAT:double precision,BINARY_DOUBLE:double precision,TIMESTAMP:timestamp,XMLTYPE:xml,BINARY_INTEGER:integer,PLS_INTEGER:integer,TIMESTAMP WITH TIME ZONE:timestamp with time zone,TIMESTAMP WITH LOCAL TIME ZONE:timestamp with time zone","description":"If you're experiencing problems in data type export, the DATA_TYPE directive will help you to redefine data type translation used in Ora2pg. The syntax is a comma separated list of \"Oracle datatype:Postgresql data type\". Here are the data type that can be redefined and their default value. If you want to replace a type with a precision and scale you need to escape the coma with a backslash. For example, if you want to replace all NUMBER(*,0) into bigint instead of numeric(38)add the following: DATA_TYPE NUMBER(*\\,0):bigint","include":false},"PG_NUMERIC_TYPE":{"value":1,"flag":true,"description":"Replace portable numeric type into PostgreSQL internal type. Oracle data type NUMBER(p,s) is approximatively converted to real and float PostgreSQL data type. If you have monetary fields or don't want rounding issues with the extra decimals you should preserve the same numeric(p,s) PostgreSQL data type. Do that only if you need very good precision because using numeric(p,s) is slower than using real or double","include":true},"PG_INTEGER_TYPE":{"value":1,"flag":true,"description":"Replace portable numeric type into PostgreSQL internal type. Oracle data type NUMBER(p) or NUMBER are converted to smallint, integer or bigint PostgreSQL data type following the length of the precision. If NUMBER without precision are set to DEFAULT_NUMERIC","include":true},"DEFAULT_NUMERIC":{"value":"bigint","description":"NUMBER() without precision are converted by default to bigint only if PG_INTEGER_TYPE is true. You can overwrite this value to any PG type, like integer or float","include":true},"ENABLE_MICROSECOND":{"value":1,"flag":true,"description":"Disable if you don't want to export milliseconds from Oracle timestamp columns. Timestamp will be formated with to_char(..., 'YYYY-MM-DD HH24:MI:SS') Enabling this directive, the default, format is 'YYYY-MM-DD HH24:MI:SS.FF'","include":true},"REPLACE_AS_BOOLEAN":{"value":"TB_NAME1:COL_NAME1 TB_NAME1:COL_NAME2 TB_NAME2:COL_NAME2","description":"Replace some columns as PostgreSQL boolean define here a list of tables and column separated by space as follows. You can also give a type and a precision to automatically convert all fields of that type as a boolean. For example: NUMBER:1 or CHAR:1 will replace any field of type number(1) or char(1) as a boolean in all exported tables","include":false},"BOOLEAN_VALUES":{"value":"yes:no y:n 1:0 true:false enabled:disabled","description":"Additional definitions of the possible boolean values in Oracle field. A space separated list of TRUE:FALSE values","include":false},"REPLACE_ZERO_DATE":{"value":"1970-01-01 00:00:00","description":"When Ora2Pg find a \"zero\" date: 0000-00-00 00:00:00 it is replaced by a NULL. This could be a problem if your column is defined with NOT NULL constraint. If you can not remove the constraint, use this directive to set an arbitral date that will be used instead. You can also use -INFINITY if you don't want to use a fake date","include":false},"MODIFY_TYPE":{"value":"","description":"Some time you need to force the destination type, for example a column exported as timestamp by Ora2Pg can be forced into type date. Value is a comma-separated list of TABLE:COLUMN:TYPE structure. If you need to use comma or space inside type definition you will have to backslash them","include":false},"TO_NUMBER_CONVERSION":{"value":"numeric","description":"By default Oracle call to function TO_NUMBER will be translated as a cast into numeric. For example, TO_NUMBER('10.1234')  is converted into PostgreSQL call to_number('10.1234')::numeric. If you want you can cast the call to integer or bigint by changing the value of the configuration directive. If you need better control of the format, just set it as value, for example: TO_NUMBER_CONVERSION 99999999999999999999.9999999999 will convert the code above as: TO_NUMBER('10.1234', '99999999999999999999.9999999999') Any value of the directive that it is not numeric, integer or bigint willbe taken as a mask format. If set to none, no conversion will be done.","include":true}},"title":"Type behaviors and redefinitions"},"GRANT":{"values":{"GEN_USER_PWD":{"value":0,"flag":true,"description":"Replace default password for extracted users during GRANT export","include":true},"FORCE_OWNER":{"value":0,"description":"By default the owner of database objects is the one you're using to connect to PostgreSQL. If you use an other user (e.g. postgres) you can force Ora2Pg to set the object owner to be the one used in the Oracle database by setting the directive to 1, or to a completely different username by setting the directive value # to that username","include":true},"FORCE_SECURITY_INVOKER":{"value":0,"description":"Enable to define all functions as SECURITY DEFINER ignoring the function's security privileges set in Oracle","include":true}},"title":"Control priviledge and owner export"},"DATA":{"values":{"DATA_LIMIT":{"value":10000,"description":"Extract data by bulk of DATA_LIMIT tuples at once. Default 10000. Note: if you set a high value be sure to have enough memory if you have millions of rows","include":true},"BLOB_LIMIT":{"value":500,"description":"When Ora2Pg detect a table with some BLOB it will automatically reduce the value of this directive by dividing it by 10 until his value is below 1000. You can control this value by setting BLOB_LIMIT. Exporting BLOB use lot of ressources, setting it to a too high value can produce OOM","include":false},"NOESCAPE":{"value":0,"flag":true,"description":"By default all data that are not of type date or time are escaped. If you experience any problem with that you can set it to 1 to disable it. This directive is only used during a COPY export type. See STANDARD_CONFORMING_STRINGS for enabling/disabling escape with INSERT statements.","include":true},"TRANSACTION":{"value":"serializable","enum":["readonly","readwrite","serializable","committed"],"description":"Change the default isolation level of the data export transaction. Default is to set the level to a serializable transaction to ensure data consistency. Here are the allowed value of this directive: readonly, readwrite, serializable and (read) committed","include":true},"STANDARD_CONFORMING_STRINGS":{"value":1,"flag":true,"description":"This controls whether ordinary string literals ('...') treat backslashes literally, as specified in SQL standard. Causes Ora2Pg to use the escape string syntax (E'...') if this parameter is not disabled. This is the exact behavior of the same option in PostgreSQL. This directive is only used during INSERT export to build INSERT statements. See NOESCAPE for enabling/disabling escape in COPY statements.","include":true},"LONGREADLEN":{"value":1047552,"description":"Set the database handle's 'LongReadLen' attribute to a value that will be the larger than the expected size of the LOB. The default is 1MB witch may not be enough to extract BLOB objects. If the size of the LOB exceeds the 'LongReadLen' DBD::Oracle will return a 'ORA-24345: A Truncation' error.  Default: 1023*1024 bytes. Important note: If you increase the value of this directive take care that DATA_LIMIT will probably needs to be reduced. Even if you only have a 1MB blob trying to read 10000 of them (the default DATA_LIMIT) all at once will require 10GB of memory. You may extract data from those table separately and set a DATA_LIMIT to 500 or lower, otherwise you may experience some out of memory","include":false},"LONGTRUNCOK":{"value":0,"flag":true,"description":"Enable to bypass the 'ORA-24345: A Truncation' error and truncate the extracted data to the LongReadLen value","include":false},"NO_LOB_LOCATOR":{"value":0,"flag":true,"description":"Disable this if you don't want to load full content of BLOB and CLOB and use LOB locators instead. This is usefull to not having to set LONGREADLEN. Note that this will not improve speed of BLOB export as most of the time is consumed by the byte escaping and in this case export is done line by line and not by chunk of DATA_LIMIT rows. Default is enabled, it will not use LOB locators for backward compatibility.","include":true},"LOB_CHUNK_SIZE":{"value":512000,"description":"Oracle recommends reading from and writing to a LOB in batches using a multiple of the LOB chunk size. This chunk size defaults to 8k (8192). Recent tests shown that the best performance can be reach with higher value like 512K or 4Mb.","include":true},"XML_PRETTY":{"value":0,"flag":true,"description":"Use getStringVal() instead of getClobVal() for XML data export. Default is enabled for backward compatibility.","include":true},"LOG_ON_ERROR":{"value":0,"flag":true,"description":"Enable this directive if you want to continue direct data import on error. When Ora2Pg receives an error in the COPY or INSERT statement from PostgreSQL it will log the statement to a file called TABLENAME_error.log in the output directory and continue to next bulk of data. Default is disabled: abort import on error.","include":true},"TRIM_TYPE":{"value":"BOTH","description":"If you want to convert CHAR(n) from Oracle into varchar(n) or text under PostgreSQL, you might want to do some triming on the data. By default Ora2Pg will auto-detect this conversion and remove any withspace at both leading and trailing position. If you just want to remove the leadings character, set the value to LEADING. If you just want to remove the trailing character, set the value to TRAILING. Default value is BOTH","include":true},"TRIM_CHAR":{"value":"-","description":"The default triming character is space, use the directive bellow if you need to change the character that will be removed. For example, set it to - if you have leading - in the char(n) field. To use space as triming charger, comment this directive, this is the default value","include":false},"INTERNAL_DATE_MAX":{"value":49,"description":"Internal timestamp retrieves from custom type are extracted in the following format: 01-JAN-77 12.00.00.000000 AM. It is impossible to know the exact century that must be used, so by default any year below 49 will be added to 2000 and others to 1900. You can use this directive to change this default value. This is only relevant if you have user defined type with a column timestamp","include":true},"FUNCTION_CHECK":{"value":1,"flag":true,"description":"Disable this directive if you want to disable check_function_bodies. SET check_function_bodies = false; It disables validation of the function body string during CREATE FUNCTION. Default is to use the postgresql.conf setting that enable it by default","include":true},"NO_BLOB_EXPORT":{"value":0,"flag":true,"description":"Do not export the contents of BLOB columns","include":true},"DATA_EXPORT_ORDER":{"value":"name","enum":["name","size"],"description":"Controls the order that table data is exported options are table name or size (small to large)","include":true},"PSQL_RELATIVE_PATH":{"value":0,"flag":true,"description":"Use 'ir' instead of 'i' in the psql command that executes the generated SQL files","include":true}},"title":"Data export behavior"},"PERFORMANCE":{"values":{"JOBS":{"value":1,"description":"Add multiprocess support to COPY, FUNCTION and PROCEDURE export type. The value is the number of process to use. Default is to not use multiprocess. This directive is used to set the number of cores to used to parallelize data import into PostgreSQL. During FUNCTION or PROCEDURE export type each function will be translated to plpgsql using a new process, the performances gain can be very important when you have tons of function to convert. There's no more limitation in parallel processing than the number of cores and the PostgreSQL I/O performance capabilities. Does not work under Windows Operating System, it is simply disabled.","include":true},"ORACLE_COPIES":{"value":1,"description":"Multiprocess support. This directive defines the number of parallel connections to Oracle when extracting data. The limit is the number of cores on your machine. This is useful if Oracle is the bottleneck. Take care that this directive can only be used if there is a column defined in DEFINED_PK","include":true},"PARALLEL_TABLES":{"value":1,"description":"Multiprocess support. This directive defines the number of tables in parallel data extraction. The limit is the number of cores on your machine. Ora2Pg will open one database connection for each parallel table extraction. This directive, when upper than 1, will invalidate ORACLE_COPIES but not JOBS. Note that this directive when set upper that 1 will also automatically enable the FILE_PER_TABLE directive if your are exporting to files","include":true},"DEFAULT_PARALLELISM_DEGREE":{"value":0,"flag":true,"description":"force Ora2Pg to use /*+ PARALLEL(tbname, degree) */ hint in queries used to export data from Oracle","include":true},"PARALLEL_MIN_ROWS":{"value":100000,"description":"Parallel mode will not be activated if the table has fewer rows than this value. This prevents unecessary Oracle process forks. Default is 100K rows","include":true},"DEFINED_PK":{"value":"TABLE:COLUMN TABLE:ROUND(COLUMN)","description":"Multiprocess support. This directive is used to split the select queries between the different connections to Oracle if ORA_COPIES is used. Ora2Pg will extract data with the following prepare statement: SELECT * FROM TABLE WHERE MOD(COLUMN, $ORA_COPIES) = ? Where $ORA_COPIES is the total number of cores used to extract data and set with ORA_COPIES directive, and ? is the current core used at execution time. This means that Ora2Pg needs to know the numeric column to use in this query. If this column is a real, float, numeric or decimal, you must add the ROUND() function with the column to round the value to the nearest integer","include":false},"DROP_INDEXES":{"value":0,"flag":true,"description":"Enabling this directive force Ora2Pg to drop all indexes on data import tables, except automatic index on primary key, and recreate them at end of data import. This may improve performance during a fresh import","include":true},"SYNCHRONOUS_COMMIT":{"value":0,"flag":true,"description":"Specifies whether transaction commit will wait for WAL records to be written to disk before the command returns a \"success\" indication to the client. This is equivalent to setting the synchronous_commit directive in a postgresql.conf file. This is only used when you load data directly to PostgreSQL, the default is off to disable synchronous commit to gain speed at writing data. Some modified versions of PostgreSQL, like Greenplum, do not have this setting, so in this case set this directive to 1, ora2pg will not try to change the setting","include":true}},"title":"Export/import performance"},"PLSQL":{"values":{"EXPORT_INVALID":{"value":0,"flag":true,"description":"Export all PL/SQL code even if it is marked as invalid. The 'VALID' or 'INVALID' status applies to functions, procedures, packages and user defined types","include":true},"PLSQL_PGSQL":{"value":1,"flag":true,"description":"Enable PLSQL to PLPSQL conversion","include":true},"NULL_EQUAL_EMPTY":{"value":0,"flag":true,"description":"Replace all conditions with a test on NULL by a call to the coalesce() function to mimic the Oracle behavior where empty field are considered equal to NULL. Ex: (field1 IS NULL) and (field2 IS NOT NULL) will be replaced by (coalesce(field1::text, '') = '') and (field2 IS NOT NULL AND field2::text <> ''). Note: if you have control on you app a better way is to change it to transform empty string into NULL because PostgreSQL makes the difference","include":true},"EMPTY_LOB_NULL":{"value":0,"flag":true,"description":"Force empty_clob() and empty_blob() to be exported as NULL instead as empty string for the first one and \\x for the second. If NULL is allowed in your column this might improve data export speed if you have lot of empty lob","include":true},"PACKAGE_AS_SCHEMA":{"value":1,"flag":true,"description":"Use schemas to emulate packages. If you don't want to export package as schema but as simple functions you might also want to replace all call to package_name.function_name. If you disable the PACKAGE_AS_SCHEMA directive then Ora2Pg will replace all call to package_name.function_name() by package_name_function_name(). Default is to use a schema to emulate package","include":true},"REWRITE_OUTER_JOIN":{"value":1,"flag":true,"description":"Enable this directive if the rewrite of Oracle native syntax (+) of OUTER JOIN is broken. This will force Ora2Pg to not rewrite such code, default is to try to rewrite simple form of right outer join for the moment","include":true},"FUNCTION_STABLE":{"value":1,"flag":true,"description":"By default Oracle functions are marked as STABLE as they can not modify data unless when used in PL/SQL with variable assignment or as conditional expression. You can force Ora2Pg to create these function as VOLATILE by disabling the FUNCTION_STABLE directive.","include":true},"COMMENT_COMMIT_ROLLBACK":{"value":0,"flag":true,"description":"By default calls to COMMIT/ROLLBACK are kept untouched by Ora2Pg to force the user to review the logic of the function. Once it is fixed in Oracle source code or you want to comment this calls enable the following directive","include":true},"STRING_CONSTANT_REGEXP":{"value":"<placeholder value=\".*\">","description":"Replace all string constant during the pl/sql to plpgsql translation. String constants are all text included between single quotes. If you have some string placeholder used in dynamic call to queries you can set a list of regexp to be temporary replaced to not break the parser. The list of regexp must use the semi colon as separato","include":false},"ALTERNATIVE_QUOTING_REGEXP":{"value":"q'{(.*)}'","flag":true,"description":"Set the regexp with the text capture to use to extract the text part. For example with a variable declared as c_sample VARCHAR2(100 CHAR) := q'{This doesn't work.}'; the regexp must be: q'{(.*)}' ora2pg use the 32989 delimiter","include":true},"USE_ORAFCE":{"value":0,"flag":true,"description":"Use functions defined in the Orafce library and prevent Ora2Pg translating calls to these function. By default Ora2pg rewrite add_month(), add_year(), date_trunc() and to_char() functions, but you may prefer to use the orafce version of these function that do not need any code transformation","include":true},"AUTONOMOUS_TRANSACTION":{"value":1,"flag":true,"description":"Enable translation of autonomous transactions into a wrapper function using dblink or pg_background extension","include":true}},"title":"SQL and PL/SQL to PLPGSQL rewriting behavior"},"ASSESSMENT":{"values":{"ESTIMATE_COST":{"value":0,"flag":true,"description":"Activate the migration cost evaluation. Must only be used with SHOW_REPORT, FUNCTION, PROCEDURE, PACKAGE and QUERY export type. Default is disabled. Note that enabling this directive will force PLSQL_PGSQL activation.","include":true},"COST_UNIT_VALUE":{"value":5,"description":"Set the value in minutes of the migration cost evaluation unit. Default is five minutes per unit","include":true},"DUMP_AS_HTML":{"value":0,"flag":true,"description":"By default when using SHOW_REPORT the migration report is generated as simple text, enabling this directive will force ora2pg to create a report in HTML format","include":true},"TOP_MAX":{"value":10,"description":"Set the total number of tables to display in the Top N per row and size list in the SHOW_TABLE and SHOW_REPORT output. Default 10","include":true},"HUMAN_DAYS_LIMIT":{"value":10,"description":"Redefined the number of human-days limit where the migration assessment level must switch from B to C. Default is set to 10 human-days","include":true},"AUDIT_USER":{"value":"USERNAME1,USERNAME2","description":"Set a comma separated list of usernames that to filter queries from the DBA_AUDIT_TRAIL table. Default is to not scan this table and to never look for queries. This parameter is used only with SHOW_REPORT and QUERY export type with no input file for queries. Note that queries will be normalized before output unlike when a file is given at input using the -i option or INPUT directive","include":false},"UUID_FUNCTION":{"value":"uuid_generate_v4","description":"By default Ora2Pg will convert call to SYS_GUID() Oracle function with a call to uuid_generate_v4() from uuid-ossp extension. You can redefined it to use the gen_random_uuid() function from pgcrypto extension by changing the function name","include":false}},"title":"Migration assessment behavior"},"POSTGRESQL":{"values":{"PG_VERSION":{"value":11,"description":"Set the PostgreSQL major version number of the target database","include":true},"BITMAP_AS_GIN":{"value":1,"flag":true,"description":"Use btree_gin extenstion to create bitmap like index with pg >= 9.4 You will need to create the extension by yourself: create extension btree_gin; Default is to create GIN index, when disabled, a btree index will be created","include":true},"PG_BACKGROUND":{"value":0,"flag":true,"description":"Use pg_background extension to create an autonomous transaction instead of using a dblink wrapper. With pg >= 9.5 only, default is to use dblink","include":true},"DBLINK_CONN":{"value":"port=5432 dbname=pgdb host=localhost user=pguser password=pgpass","description":"By default if you have an autonomous transaction translated using dblink extension instead of pg_background the connection is defined using the values set with PG_DSN, PG_USER and PG_PWD. If you want to fully override the connection string use this directive as follow to set the connection in the autonomous transaction wrapper function","include":false},"PG_SUPPORTS_SUBSTR":{"value":1,"flag":true,"description":"Some versions of PostgreSQL like Redshift doesn't support substr() and it need to be replaced by a call to substring(). In this case, disable it","include":true}},"title":"Identify which PostgreSQL features are available"},"SPATIAL":{"values":{"AUTODETECT_SPATIAL_TYPE":{"value":1,"description":"Enable this directive if you want Ora2Pg to detect the real spatial type and dimensions used in a spatial column. By default Ora2Pg will look at spatial indexes to see if the layer_gtype and sdo_indx_dims constraint parameters have been set, otherwise column will be created with the non-constrained \"geometry\" type. Enabling this feature will force Ora2Pg to scan a sample of 50000 lines to look at the GTYPE used. You can increase or reduce the sample by setting the value of AUTODETECT_SPATIAL_TYPE to the desired number of lines.","include":false},"CONVERT_SRID":{"value":1,"description":"Disable this directive if you don't want to automatically convert SRID to EPSG using the sdo_cs.map_oracle_srid_to_epsg() function. Default: enabled. If the SDO_SRID returned by Oracle is NULL, it will be replaced by the default value 8307 converted to its EPSG value: 4326 (see DEFAULT_SRID) If the value is greater than 1, all SRID will be forced to this value, in this case DEFAULT_SRID will not be used when Oracle returns a null value and the value will be forced to CONVERT_SRID. Note that it is also possible to set the EPSG value on Oracle side when sdo_cs.map_oracle_srid_to_epsg() return NULL if your want to force the value: Ex: system> UPDATE sdo_coord_ref_sys SET legacy_code=41014 WHERE srid = 27572;","include":true},"DEFAULT_SRID":{"value":4326,"description":"Use this directive to override the default EPSG SRID to used: 4326. Can be overwritten by CONVERT_SRID","include":true},"GEOMETRY_EXTRACT_TYPE":{"value":"INTERNAL","enum":["INTERNAL","WKT","WKB"],"description":" This directive can take three values: WKT (default), WKB and INTERNAL. When it is set to WKT, Ora2Pg will use SDO_UTIL.TO_WKTGEOMETRY() to extract the geometry data. When it is set to WKB, Ora2Pg will use the binary output using SDO_UTIL.TO_WKBGEOMETRY(). If those two extract type are called at Oracle side, they are slow and you can easily reach Out Of Memory when you have lot of rows. Also WKB is not able to export 3D geometry and some geometries like CURVEPOLYGON. In this case you may use the INTERNAL extraction type. It will use a pure Perl library to convert the SDO_GEOMETRY data into a WKT representation, the translation is done on Ora2Pg side. This is a work in progress, please validate your exported data geometries before use.","include":true}},"title":"Spatial geometry export"},"FDW":{"values":{"FDW_SERVER":{"value":"orcl","description":"Set the name of the foreign data server that is used in the \"CREATE SERVER name FOREIGN DATA WRAPPER oracle_fdw ...\" command. This name will  be used in the \"CREATE FOREIGN TABLE ...\" SQL command. Default is arbitrary set to orcl. This only concerns exports of type FDW","include":true}},"title":"Foreign Data Wrapper export"},"MYSQL":{"values":{"MYSQL_PIPES_AS_CONCAT":{"value":0,"flag":true,"description":"Enable this if double pipe and double ampersand (|| and &&) should not be taken as equivalent to OR and AND. It depend of the variable @sql_mode, Use it only if Ora2Pg fail on auto detecting this behavior","include":true},"MYSQL_INTERNAL_EXTRACT_FORMAT":{"value":0,"flag":true,"description":"Enable this directive if you want EXTRACT() replacement to use the internal format returned as an integer, for example DD HH24:MM:SS will be replaced with format; DDHH24MMSS::bigint, this depend of your apps usage","include":true}},"title":"MySQL export behavior"}}